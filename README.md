# Orientation & Integrity AI

This repository is a unified project space focused on orientation integrity in AI systems — including temporal anchoring, contextual stability, and second-order system awareness.

The work is organized into three parallel components (TAI, 2SAI, and essays). TAI is the primary technical framework of the project, while 2SAI and the essays provide complementary system-level and explanatory layers.

The repository is intentionally structured as a shared reference space rather than a single-paper archive.

# TAI – Temporal Anchoring for AI Systems

This repository contains the TAI framework, a system-level mechanism for reducing avoidable AI errors caused by temporal misalignment.

The core document is provided as a PDF.

## License
This work is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0).
Attribution is required. If you implement or build upon this work, the author would appreciate being informed.
